{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"torch2trt torch2trt is a PyTorch to TensorRT converter which utilizes the TensorRT Python API. The converter is Easy to use - Convert modules with a single function call torch2trt Easy to extend - Write your own layer converter in Python and register it with @tensorrt_converter If you find an issue, please let us know !","title":"Home"},{"location":"index.html#torch2trt","text":"torch2trt is a PyTorch to TensorRT converter which utilizes the TensorRT Python API. The converter is Easy to use - Convert modules with a single function call torch2trt Easy to extend - Write your own layer converter in Python and register it with @tensorrt_converter If you find an issue, please let us know !","title":"torch2trt"},{"location":"converters.html","text":"","title":"Converters"},{"location":"benchmarks/jetson_nano.html","text":"Jetson Nano Name Data Type Input Shapes torch2trt kwargs Max Error Throughput (PyTorch) Throughput (TensorRT) Latency (PyTorch) Latency (TensorRT) torchvision.models.alexnet.alexnet float16 [(1, 3, 224, 224)] 2.29E-05 46.4 69.9 22.1 14.7 torchvision.models.squeezenet.squeezenet1_0 float16 [(1, 3, 224, 224)] 1.20E-02 44 137 24.2 7.6 torchvision.models.squeezenet.squeezenet1_1 float16 [(1, 3, 224, 224)] 9.77E-04 76.6 248 14 4.34 torchvision.models.resnet.resnet18 float16 [(1, 3, 224, 224)] 5.86E-03 29.4 90.2 34.7 11.4 torchvision.models.resnet.resnet34 float16 [(1, 3, 224, 224)] 1.56E-01 15.5 50.7 64.8 20.2 torchvision.models.resnet.resnet50 float16 [(1, 3, 224, 224)] 6.45E-02 12.4 34.2 81.7 29.8 torchvision.models.resnet.resnet101 float16 [(1, 3, 224, 224)] 1.01E+03 7.18 19.9 141 51.1 torchvision.models.resnet.resnet152 float16 [(1, 3, 224, 224)] 0.00E+00 4.96 14.1 204 72.3 torchvision.models.densenet.densenet121 float16 [(1, 3, 224, 224)] 3.42E-03 11.5 41.9 84.5 24.8 torchvision.models.densenet.densenet169 float16 [(1, 3, 224, 224)] 5.86E-03 8.25 33.2 118 31.2 torchvision.models.densenet.densenet201 float16 [(1, 3, 224, 224)] 3.42E-03 6.84 25.4 141 40.8 torchvision.models.densenet.densenet161 float16 [(1, 3, 224, 224)] 4.15E-03 4.71 15.6 247 65.8 torchvision.models.vgg.vgg11 float16 [(1, 3, 224, 224)] 3.51E-04 8.9 18.3 114 55.1 torchvision.models.vgg.vgg13 float16 [(1, 3, 224, 224)] 3.07E-04 6.53 14.7 156 68.7 torchvision.models.vgg.vgg16 float16 [(1, 3, 224, 224)] 4.58E-04 5.09 11.9 201 85.1 torchvision.models.vgg.vgg11_bn float16 [(1, 3, 224, 224)] 3.81E-04 8.74 18.4 117 54.8 torchvision.models.vgg.vgg13_bn float16 [(1, 3, 224, 224)] 5.19E-04 6.31 14.8 162 68.5 torchvision.models.vgg.vgg16_bn float16 [(1, 3, 224, 224)] 9.77E-04 4.96 12 207 84.3","title":"Jetson Nano"},{"location":"benchmarks/jetson_nano.html#jetson-nano","text":"Name Data Type Input Shapes torch2trt kwargs Max Error Throughput (PyTorch) Throughput (TensorRT) Latency (PyTorch) Latency (TensorRT) torchvision.models.alexnet.alexnet float16 [(1, 3, 224, 224)] 2.29E-05 46.4 69.9 22.1 14.7 torchvision.models.squeezenet.squeezenet1_0 float16 [(1, 3, 224, 224)] 1.20E-02 44 137 24.2 7.6 torchvision.models.squeezenet.squeezenet1_1 float16 [(1, 3, 224, 224)] 9.77E-04 76.6 248 14 4.34 torchvision.models.resnet.resnet18 float16 [(1, 3, 224, 224)] 5.86E-03 29.4 90.2 34.7 11.4 torchvision.models.resnet.resnet34 float16 [(1, 3, 224, 224)] 1.56E-01 15.5 50.7 64.8 20.2 torchvision.models.resnet.resnet50 float16 [(1, 3, 224, 224)] 6.45E-02 12.4 34.2 81.7 29.8 torchvision.models.resnet.resnet101 float16 [(1, 3, 224, 224)] 1.01E+03 7.18 19.9 141 51.1 torchvision.models.resnet.resnet152 float16 [(1, 3, 224, 224)] 0.00E+00 4.96 14.1 204 72.3 torchvision.models.densenet.densenet121 float16 [(1, 3, 224, 224)] 3.42E-03 11.5 41.9 84.5 24.8 torchvision.models.densenet.densenet169 float16 [(1, 3, 224, 224)] 5.86E-03 8.25 33.2 118 31.2 torchvision.models.densenet.densenet201 float16 [(1, 3, 224, 224)] 3.42E-03 6.84 25.4 141 40.8 torchvision.models.densenet.densenet161 float16 [(1, 3, 224, 224)] 4.15E-03 4.71 15.6 247 65.8 torchvision.models.vgg.vgg11 float16 [(1, 3, 224, 224)] 3.51E-04 8.9 18.3 114 55.1 torchvision.models.vgg.vgg13 float16 [(1, 3, 224, 224)] 3.07E-04 6.53 14.7 156 68.7 torchvision.models.vgg.vgg16 float16 [(1, 3, 224, 224)] 4.58E-04 5.09 11.9 201 85.1 torchvision.models.vgg.vgg11_bn float16 [(1, 3, 224, 224)] 3.81E-04 8.74 18.4 117 54.8 torchvision.models.vgg.vgg13_bn float16 [(1, 3, 224, 224)] 5.19E-04 6.31 14.8 162 68.5 torchvision.models.vgg.vgg16_bn float16 [(1, 3, 224, 224)] 9.77E-04 4.96 12 207 84.3","title":"Jetson Nano"},{"location":"benchmarks/jetson_xavier.html","text":"Jetson Xavier Name Data Type Input Shapes torch2trt kwargs Max Error Throughput (PyTorch) Throughput (TensorRT) Latency (PyTorch) Latency (TensorRT) torch2trt.tests.torchvision.classification.alexnet float16 [(1, 3, 224, 224)] 7.63E-05 251 565 4.96 2.02 torch2trt.tests.torchvision.classification.squeezenet1_0 float16 [(1, 3, 224, 224)] 9.77E-04 121 834 8.04 1.49 torch2trt.tests.torchvision.classification.squeezenet1_1 float16 [(1, 3, 224, 224)] 9.77E-04 125 1.29e+03 8.01 1.02 torch2trt.tests.torchvision.classification.resnet18 float16 [(1, 3, 224, 224)] 9.77E-03 136 722 7.33 1.64 torch2trt.tests.torchvision.classification.resnet34 float16 [(1, 3, 224, 224)] 2.50E-01 77.8 396 12.9 2.79 torch2trt.tests.torchvision.classification.resnet50 float16 [(1, 3, 224, 224)] 1.09E-01 55.8 326 17.9 3.37 torch2trt.tests.torchvision.classification.resnet101 float16 [(1, 3, 224, 224)] 0.00E+00 28.3 175 35.1 6.04 torch2trt.tests.torchvision.classification.resnet152 float16 [(1, 3, 224, 224)] 0.00E+00 18.8 122 53.2 8.57 torch2trt.tests.torchvision.classification.densenet121 float16 [(1, 3, 224, 224)] 7.81E-03 20.9 76.6 47.5 13 torch2trt.tests.torchvision.classification.densenet169 float16 [(1, 3, 224, 224)] 3.91E-03 14.8 41.7 66.7 23.7 torch2trt.tests.torchvision.classification.densenet201 float16 [(1, 3, 224, 224)] 4.88E-03 12.6 30.2 79.1 33 torch2trt.tests.torchvision.classification.densenet161 float16 [(1, 3, 224, 224)] 4.88E-03 16.1 43.7 62.1 23 torch2trt.tests.torchvision.classification.vgg11 float16 [(1, 3, 224, 224)] 2.56E-03 84.8 201 12.1 5.24 torch2trt.tests.torchvision.classification.vgg13 float16 [(1, 3, 224, 224)] 2.24E-03 71.1 165 14.3 6.34 torch2trt.tests.torchvision.classification.vgg16 float16 [(1, 3, 224, 224)] 3.78E-03 61.5 139 16.5 7.46 torch2trt.tests.torchvision.classification.vgg19 float16 [(1, 3, 224, 224)] 2.81E-03 54.1 120 18.7 8.61 torch2trt.tests.torchvision.classification.vgg11_bn float16 [(1, 3, 224, 224)] 2.20E-03 81.5 200 12.5 5.27 torch2trt.tests.torchvision.classification.vgg13_bn float16 [(1, 3, 224, 224)] 1.71E-03 67.5 165 15.1 6.33 torch2trt.tests.torchvision.classification.vgg16_bn float16 [(1, 3, 224, 224)] 2.87E-03 58.3 139 17.4 7.48 torch2trt.tests.torchvision.classification.vgg19_bn float16 [(1, 3, 224, 224)] 2.44E-03 51.4 120 19.7 8.61 torch2trt.tests.torchvision.classification.mobilenet_v2 float16 [(1, 3, 224, 224)] 0.00E+00 64.8 723 15.4 1.67 torch2trt.tests.torchvision.classification.shufflenet_v2_x0_5 float16 [(1, 3, 224, 224)] 1.53E-05 51.2 463 19.4 2.17 torch2trt.tests.torchvision.classification.shufflenet_v2_x1_0 float16 [(1, 3, 224, 224)] 1.53E-05 49.4 419 20.4 2.43 torch2trt.tests.torchvision.classification.shufflenet_v2_x1_5 float16 [(1, 3, 224, 224)] 1.53E-05 51.4 426 19.6 2.37 torch2trt.tests.torchvision.classification.shufflenet_v2_x2_0 float16 [(1, 3, 224, 224)] 1.53E-05 48.2 419 20.8 2.48 torch2trt.tests.torchvision.classification.mnasnet0_5 float16 [(1, 3, 224, 224)] 2.03E-06 67.8 883 14.9 1.4 torch2trt.tests.torchvision.classification.mnasnet0_75 float16 [(1, 3, 224, 224)] 0.00E+00 67.6 751 14.8 1.6 torch2trt.tests.torchvision.classification.mnasnet1_0 float16 [(1, 3, 224, 224)] 0.00E+00 65.7 667 15.2 1.77 torch2trt.tests.torchvision.classification.mnasnet1_3 float16 [(1, 3, 224, 224)] 0.00E+00 67.4 573 15 2.02","title":"Jetson Xavier"},{"location":"benchmarks/jetson_xavier.html#jetson-xavier","text":"Name Data Type Input Shapes torch2trt kwargs Max Error Throughput (PyTorch) Throughput (TensorRT) Latency (PyTorch) Latency (TensorRT) torch2trt.tests.torchvision.classification.alexnet float16 [(1, 3, 224, 224)] 7.63E-05 251 565 4.96 2.02 torch2trt.tests.torchvision.classification.squeezenet1_0 float16 [(1, 3, 224, 224)] 9.77E-04 121 834 8.04 1.49 torch2trt.tests.torchvision.classification.squeezenet1_1 float16 [(1, 3, 224, 224)] 9.77E-04 125 1.29e+03 8.01 1.02 torch2trt.tests.torchvision.classification.resnet18 float16 [(1, 3, 224, 224)] 9.77E-03 136 722 7.33 1.64 torch2trt.tests.torchvision.classification.resnet34 float16 [(1, 3, 224, 224)] 2.50E-01 77.8 396 12.9 2.79 torch2trt.tests.torchvision.classification.resnet50 float16 [(1, 3, 224, 224)] 1.09E-01 55.8 326 17.9 3.37 torch2trt.tests.torchvision.classification.resnet101 float16 [(1, 3, 224, 224)] 0.00E+00 28.3 175 35.1 6.04 torch2trt.tests.torchvision.classification.resnet152 float16 [(1, 3, 224, 224)] 0.00E+00 18.8 122 53.2 8.57 torch2trt.tests.torchvision.classification.densenet121 float16 [(1, 3, 224, 224)] 7.81E-03 20.9 76.6 47.5 13 torch2trt.tests.torchvision.classification.densenet169 float16 [(1, 3, 224, 224)] 3.91E-03 14.8 41.7 66.7 23.7 torch2trt.tests.torchvision.classification.densenet201 float16 [(1, 3, 224, 224)] 4.88E-03 12.6 30.2 79.1 33 torch2trt.tests.torchvision.classification.densenet161 float16 [(1, 3, 224, 224)] 4.88E-03 16.1 43.7 62.1 23 torch2trt.tests.torchvision.classification.vgg11 float16 [(1, 3, 224, 224)] 2.56E-03 84.8 201 12.1 5.24 torch2trt.tests.torchvision.classification.vgg13 float16 [(1, 3, 224, 224)] 2.24E-03 71.1 165 14.3 6.34 torch2trt.tests.torchvision.classification.vgg16 float16 [(1, 3, 224, 224)] 3.78E-03 61.5 139 16.5 7.46 torch2trt.tests.torchvision.classification.vgg19 float16 [(1, 3, 224, 224)] 2.81E-03 54.1 120 18.7 8.61 torch2trt.tests.torchvision.classification.vgg11_bn float16 [(1, 3, 224, 224)] 2.20E-03 81.5 200 12.5 5.27 torch2trt.tests.torchvision.classification.vgg13_bn float16 [(1, 3, 224, 224)] 1.71E-03 67.5 165 15.1 6.33 torch2trt.tests.torchvision.classification.vgg16_bn float16 [(1, 3, 224, 224)] 2.87E-03 58.3 139 17.4 7.48 torch2trt.tests.torchvision.classification.vgg19_bn float16 [(1, 3, 224, 224)] 2.44E-03 51.4 120 19.7 8.61 torch2trt.tests.torchvision.classification.mobilenet_v2 float16 [(1, 3, 224, 224)] 0.00E+00 64.8 723 15.4 1.67 torch2trt.tests.torchvision.classification.shufflenet_v2_x0_5 float16 [(1, 3, 224, 224)] 1.53E-05 51.2 463 19.4 2.17 torch2trt.tests.torchvision.classification.shufflenet_v2_x1_0 float16 [(1, 3, 224, 224)] 1.53E-05 49.4 419 20.4 2.43 torch2trt.tests.torchvision.classification.shufflenet_v2_x1_5 float16 [(1, 3, 224, 224)] 1.53E-05 51.4 426 19.6 2.37 torch2trt.tests.torchvision.classification.shufflenet_v2_x2_0 float16 [(1, 3, 224, 224)] 1.53E-05 48.2 419 20.8 2.48 torch2trt.tests.torchvision.classification.mnasnet0_5 float16 [(1, 3, 224, 224)] 2.03E-06 67.8 883 14.9 1.4 torch2trt.tests.torchvision.classification.mnasnet0_75 float16 [(1, 3, 224, 224)] 0.00E+00 67.6 751 14.8 1.6 torch2trt.tests.torchvision.classification.mnasnet1_0 float16 [(1, 3, 224, 224)] 0.00E+00 65.7 667 15.2 1.77 torch2trt.tests.torchvision.classification.mnasnet1_3 float16 [(1, 3, 224, 224)] 0.00E+00 67.4 573 15 2.02","title":"Jetson Xavier"},{"location":"usage/conversion.html","text":"","title":"Conversion"}]}