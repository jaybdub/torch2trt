


<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      <link rel="shortcut icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-5.5.11">
    
    
      
        <title>Reduced Precision - torch2trt</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.860688db.min.css">
      
        <link rel="stylesheet" href="../assets/stylesheets/palette.943997b5.min.css">
      
      
        
        
        <meta name="theme-color" content="#4cae4f">
      
    
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style>
      
    
    
    
      <link rel="stylesheet" href="../css/version-select.css">
    
    
      
        
<script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-135919510-3","auto"),ga("set","anonymizeIp",!0),ga("send","pageview"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){if(this.value){var e=document.location.pathname;ga("send","pageview",e+"?q="+this.value)}})}),document.addEventListener("DOMContentSwitch",function(){ga("send","pageview",document.location.pathname)})</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>
      
    
    
  </head>
  
  
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="green" data-md-color-accent="">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#reduced-precision" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid" aria-label="Header">
    <a href=".." title="torch2trt" class="md-header-nav__button md-logo" aria-label="torch2trt">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    <label class="md-header-nav__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header-nav__title" data-md-component="header-title">
      
        <div class="md-header-nav__ellipsis">
          <span class="md-header-nav__topic md-ellipsis">
            torch2trt
          </span>
          <span class="md-header-nav__topic md-ellipsis">
            
              Reduced Precision
            
          </span>
        </div>
      
    </div>
    
      <label class="md-header-nav__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active">
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" data-md-component="search-reset" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header-nav__source">
        
<a href="https://github.com/NVIDIA-AI-IOT/torch2trt/" title="Go to repository" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
        
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="torch2trt" class="md-nav__button md-logo" aria-label="torch2trt">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    torch2trt
  </label>
  
    <div class="md-nav__source">
      
<a href="https://github.com/NVIDIA-AI-IOT/torch2trt/" title="Go to repository" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href="../index.html" title="Home" class="md-nav__link">
      Home
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../getting_started.html" title="Getting Started" class="md-nav__link">
      Getting Started
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3" checked>
    
    <label class="md-nav__link" for="nav-3">
      Usage
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="Usage" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        <span class="md-nav__icon md-icon"></span>
        Usage
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="basic_usage.html" title="Basic Usage" class="md-nav__link">
      Basic Usage
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
    <a href="reduced_precision.html" title="Reduced Precision" class="md-nav__link md-nav__link--active">
      Reduced Precision
    </a>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="custom_converter.html" title="Custom Converter" class="md-nav__link">
      Custom Converter
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../converters.html" title="Converters" class="md-nav__link">
      Converters
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-5" type="checkbox" id="nav-5">
    
    <label class="md-nav__link" for="nav-5">
      Benchmarks
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="Benchmarks" data-md-level="1">
      <label class="md-nav__title" for="nav-5">
        <span class="md-nav__icon md-icon"></span>
        Benchmarks
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../benchmarks/jetson_nano.html" title="Jetson Nano" class="md-nav__link">
      Jetson Nano
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../benchmarks/jetson_xavier.html" title="Jetson Xavier" class="md-nav__link">
      Jetson Xavier
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../CONTRIBUTING.html" title="Contributing" class="md-nav__link">
      Contributing
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../see_also.html" title="See Also" class="md-nav__link">
      See Also
    </a>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
    
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/NVIDIA-AI-IOT/torch2trt/blob/master/usage/reduced_precision.md" title="Edit this page" class="md-content__button md-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg>
                  </a>
                
                
                  
                
                
                <h1 id="reduced-precision">Reduced Precision</h1>
<p>For certain platforms, reduced precision can result in substantial improvements in throughput,
often with little impact on model accuracy.</p>
<h1 id="support-matrix">Support Matrix</h1>
<p>Below is a table of layer precision support for various NVIDIA platforms.</p>
<table>
<thead>
<tr>
<th>Platform</th>
<th>FP16</th>
<th>INT8</th>
</tr>
</thead>
<tbody>
<tr>
<td>Jetson Nano</td>
<td><img alt="X" src="../images/check.svg" /></td>
<td></td>
</tr>
<tr>
<td>Jetson TX2</td>
<td><img alt="X" src="../images/check.svg" /></td>
<td><img alt="X" src="../images/check.svg" /></td>
</tr>
<tr>
<td>Jetson Xavier NX</td>
<td><img alt="X" src="../images/check.svg" /></td>
<td><img alt="X" src="../images/check.svg" /></td>
</tr>
<tr>
<td>Jetson AGX Xavier</td>
<td><img alt="X" src="../images/check.svg" /></td>
<td><img alt="X" src="../images/check.svg" /></td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If the platform you're using is missing from this table or you spot anything incorrect
please <a href="https://github.com/NVIDIA-AI-IOT/torch2trt">let us know</a>.</p>
</div>
<h2 id="fp16-precision">FP16 Precision</h2>
<p>To enable support for fp16 precision with TensorRT, torch2trt exposes the <code>fp16_mode</code> parameter.
Converting a model with <code>fp16_mode=True</code> allows the TensorRT optimizer to select layers with fp16
precision.</p>
<div class="highlight"><pre><span></span><code><span class="n">model_trt</span> <span class="o">=</span> <span class="n">torch2trt</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">[</span><span class="n">data</span><span class="p">],</span> <span class="n">fp16_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>

<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When <code>fp16_mode=True</code>, this does not necessarily mean that TensorRT will select FP16 layers.
The optimizer attempts to automatically select tactics which result in the best performance.</p>
</div>
<h2 id="int8-precision">INT8 Precision</h2>
<p>torch2trt also supports int8 precision with TensorRT with the <code>int8_mode</code> parameter.  Unlike fp16 and fp32 precision, switching
to in8 precision often requires calibration to avoid a significant drop in accuracy.  </p>
<h3 id="input-data-calibration">Input Data Calibration</h3>
<p>By default
torch2trt will calibrate using the input data provided.  For example, if you wanted
to calibrate on a set of 64 random normal images you could do.</p>
<div class="highlight"><pre><span></span><code><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="n">model_trt</span> <span class="o">=</span> <span class="n">torch2trt</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">[</span><span class="n">data</span><span class="p">],</span> <span class="n">int8_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>

<h3 id="dataset-calibration">Dataset Calibration</h3>
<p>In many instances, you may want to calibrate on more data than fits in memory.  For this reason,
torch2trt exposes the <code>int8_calibration_dataset</code> parameter.  This parameter takes an input
dataset that is used for calibration.  If this parameter is specified, the input data is 
ignored during calibration.  You create an input dataset by defining
a class which implements the <code>__len__</code> and <code>__getitem__</code> methods.  </p>
<ul>
<li>The <code>__len__</code> method should return the number of calibration samples</li>
<li>The <code>__getitem__</code> method must return a single calibration sample.  This is a list of input tensors to the model.  Each tensor should match the shape
you provide to the <code>inputs</code> parameter when calling <code>torch2trt</code>.</li>
</ul>
<p>For example, say you trained an image classification network using the PyTorch <a href="https://pytorch.org/docs/stable/torchvision/datasets.html#imagefolder"><code>ImageFolder</code></a> dataset.
You could wrap this dataset for calibration, by defining a new dataset which returns only the images without labels in list format.</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">torchvision.datasets</span> <span class="kn">import</span> <span class="n">ImageFolder</span>
<span class="kn">from</span> <span class="nn">torchvision.transforms</span> <span class="kn">import</span> <span class="n">ToTensor</span><span class="p">,</span> <span class="n">Compose</span><span class="p">,</span> <span class="n">Normalize</span>


<span class="k">class</span> <span class="nc">ImageFolderCalibDataset</span><span class="p">():</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">root</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">ImageFolder</span><span class="p">(</span>
            <span class="n">root</span><span class="o">=</span><span class="n">root</span><span class="p">,</span> 
            <span class="n">transform</span><span class="o">=</span><span class="n">Compose</span><span class="p">([</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">((</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)),</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">([</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span>
            <span class="p">])</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="n">image</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>  <span class="c1"># add batch dimension</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">image</span><span class="p">]</span>
</code></pre></div>

<p>You would then provide this calibration dataset to torch2trt as follows</p>
<div class="highlight"><pre><span></span><code><span class="n">dataset</span> <span class="o">=</span> <span class="n">ImageFolderCalibDataset</span><span class="p">(</span><span class="s1">&#39;images&#39;</span><span class="p">)</span>

<span class="n">model_trt</span> <span class="o">=</span> <span class="n">torch2trt</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">[</span><span class="n">data</span><span class="p">],</span> <span class="n">int8_calib_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">)</span>
</code></pre></div>

<h3 id="calibration-algorithm">Calibration Algorithm</h3>
<p>To override the default calibration algorithm that torch2trt uses, you can set the <code>int8_calib_algoirthm</code>
to the <a href="https://docs.nvidia.com/deeplearning/tensorrt/api/python_api/infer/Int8/Calibrator.html#iint8calibrator"><code>tensorrt.CalibrationAlgoType</code></a>
that you wish to use.  For example, to use the minmax calibration algoirthm you would do</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">tensorrt</span> <span class="k">as</span> <span class="nn">trt</span>

<span class="n">model_trt</span> <span class="o">=</span> <span class="n">torch2trt</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">[</span><span class="n">data</span><span class="p">],</span> <span class="n">int8_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">int8_calib_algorithm</span><span class="o">=</span><span class="n">trt</span><span class="o">.</span><span class="n">CalibrationAlgoType</span><span class="o">.</span><span class="n">MINMAX_CALIBRATION</span><span class="p">)</span>
</code></pre></div>

<h3 id="calibration-batch-size">Calibration Batch Size</h3>
<p>During calibration, torch2trt pulls data in batches for the TensorRT calibrator.  In some instances
<a href="https://github.com/NVIDIA-AI-IOT/torch2trt/pull/398">developers have found</a> that the calibration batch size can impact the calibrated model accuracy.  To set the calibration batch size, you can set the <code>int8_calib_batch_size</code>
parameter.  For example, to use a calibration batch size of 32 you could do</p>
<div class="highlight"><pre><span></span><code><span class="n">model_trt</span> <span class="o">=</span> <span class="n">torch2trt</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">[</span><span class="n">data</span><span class="p">],</span> <span class="n">int8_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">int8_calib_batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
</code></pre></div>

<h2 id="binding-data-types">Binding Data Types</h2>
<p>The data type of input and output bindings in TensorRT are determined by the original
PyTorch module input and output data types.
This does not directly impact whether the TensorRT optimizer will internally use fp16 or int8 precision.</p>
<p>For example, to create a model with half precision bindings, you would do the following</p>
<div class="highlight"><pre><span></span><code><span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

<span class="n">model_trt</span> <span class="o">=</span> <span class="n">torch2trt</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">[</span><span class="n">data</span><span class="p">],</span> <span class="n">fp16_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>

<p>In this instance, the optimizer may choose to use fp16 precision layers internally, but the
input and output data types are fp32.  To use fp16 precision input and output bindings you would do</p>
<div class="highlight"><pre><span></span><code><span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">half</span><span class="p">()</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">half</span><span class="p">()</span>

<span class="n">model_trt</span> <span class="o">=</span> <span class="n">torch2trt</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">[</span><span class="n">data</span><span class="p">],</span> <span class="n">fp16_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>

<p>Now, the input and output bindings of the model are half precision, and internally the optimizer may
choose to select fp16 layers as well.</p>
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid" aria-label="Footer">
        
          <a href="basic_usage.html" title="Basic Usage" class="md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
            </div>
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Basic Usage
              </div>
            </div>
          </a>
        
        
          <a href="custom_converter.html" title="Custom Converter" class="md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Custom Converter
              </div>
            </div>
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/vendor.df0def68.min.js"></script>
      <script src="../assets/javascripts/bundle.ba57d267.min.js"></script><script id="__lang" type="application/json">{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents"}</script>
      
      <script>
        app = initialize({
          base: "..",
          features: [],
          search: Object.assign({
            worker: "../assets/javascripts/worker/search.5eca75d3.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script>
      
        <script src="../js/version-select.js"></script>
      
    
  </body>
</html>