{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_id(node):\n",
    "    return node.scopeName() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_inputs(graph):\n",
    "    \"\"\"Returns inputs of graph as list of torch._C.Value\"\"\"\n",
    "    return list(graph.inputs())\n",
    "\n",
    "def graph_outputs(graph):\n",
    "    \"\"\"Returns outputs of graph as list of torch._C.Value\"\"\"\n",
    "    return list(graph.outputs())\n",
    "\n",
    "def val_size(val):\n",
    "    return val.type().sizes()\n",
    "\n",
    "def val_inputs(val):\n",
    "    return list(val.node().inputs())\n",
    "\n",
    "def val_outputs(val):\n",
    "    return list(val.node().outputs())\n",
    "\n",
    "def val_kind(val):\n",
    "    return val.node().kind()\n",
    "\n",
    "def val_is_tensor(val):\n",
    "    return val.isCompleteTensor()\n",
    "\n",
    "def val_debug_name(val):\n",
    "    return val.debugName()\n",
    "\n",
    "def val_scope_name(val):\n",
    "    return val.node().scopeName()\n",
    "\n",
    "def val_tensor(val):\n",
    "    return val.node().t('value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MyModule, self).__init__()\n",
    "        self.a = torch.randn(1, 3, 1, 1)\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        return x * self.a * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-211-967a2f786d2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel_jit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_jit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/jit/__init__.py\u001b[0m in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    770\u001b[0m         return trace_module(func, {'forward': example_inputs}, None,\n\u001b[1;32m    771\u001b[0m                             \u001b[0mcheck_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrap_check_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m                             check_tolerance, _force_outplace, _module_class)\n\u001b[0m\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m     if (hasattr(func, '__self__') and isinstance(func.__self__, torch.nn.Module) and\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/jit/__init__.py\u001b[0m in \u001b[0;36mtrace_module\u001b[0;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmethod_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"forward\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[0mexample_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m         \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_method_from_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_lookup_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_force_outplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m         \u001b[0mcheck_trace_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    543\u001b[0m                 \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0mtracing_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_traced_module_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m             \u001b[0mtracing_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "model = MyModule()\n",
    "\n",
    "data = torch.zeros((1, 3, 224, 224))\n",
    "\n",
    "model_jit = torch.jit.trace(model, [data])\n",
    "\n",
    "graph = model_jit.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONVERTERS = {}\n",
    "\n",
    "\n",
    "def tensorrt_converter(method):\n",
    "    def register_converter(converter):\n",
    "        CONVERTERS[method] = converter\n",
    "        return converter\n",
    "    return register_converter\n",
    "\n",
    "\n",
    "class Context():\n",
    "    \n",
    "    def __init__(self, graph, network, converters=CONVERTERS):\n",
    "        self.graph = graph\n",
    "        self.network = network\n",
    "        self.tensors = {}\n",
    "        self.converters = CONVERTERS\n",
    "\n",
    "    def get_trt(self, val):\n",
    "        print('Val %s' % val.debugName())\n",
    "        if val.debugName() in self.tensors:\n",
    "            return self.tensors[val.debugName()]  # get tensor directly\n",
    "        elif val.node().kind() in self.converters:\n",
    "            print('Calling converter for %s' % val.node().kind())\n",
    "            self.converters[val.node().kind()](self, val.node())  # attempt recursive conversion\n",
    "            return self.tensors[val.debugName()]  # tensor should now be set...\n",
    "        else:\n",
    "            raise KeyError('No converter found for %s' % val.node().kind())\n",
    "    \n",
    "    def set_trt(self, val, val_trt):\n",
    "        if val.debugName() not in self.tensors:\n",
    "            self.tensors[val.debugName()] = val_trt\n",
    "        else:\n",
    "            raise RuntimeException('TensorRT value already found in graph')\n",
    "\n",
    "            \n",
    "def torch2trt(model, data):\n",
    "    \n",
    "    model_jit = torch.jit.trace(model, data)\n",
    "    graph = model_jit.graph\n",
    "    \n",
    "    logger = trt.Logger()\n",
    "    builder = trt.Builder(logger)\n",
    "    \n",
    "    ctx = Context(graph, builder.create_network())\n",
    "    \n",
    "    for output in graph_outputs(graph):\n",
    "        \n",
    "        output_trt = ctx.get_trt(output)\n",
    "        \n",
    "        # now, ctx.trt_tensors\n",
    "        ctx.network.mark_output(output_trt)\n",
    "    return ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalar_type_to_trt(dtype):\n",
    "    if dtype == 'Float':\n",
    "        return trt.float32\n",
    "    elif dtype == 'Half':\n",
    "        return trt.float16\n",
    "    else:\n",
    "        raise TypeError('%s is not supported by tensorrt' % dtype)\n",
    "\n",
    "def torch_dtype_to_trt(dtype):\n",
    "    if dtype == torch.int8:\n",
    "        return trt.int8\n",
    "    elif dtype == torch.int32:\n",
    "        return trt.int32\n",
    "    elif dtype == torch.float16:\n",
    "        return trt.float16\n",
    "    elif dtype == torch.float32:\n",
    "        return trt.float32\n",
    "    else:\n",
    "        raise TypeError('%s is not supported by tensorrt' % dtype)\n",
    "\n",
    "\n",
    "def torch_dtype_from_trt(dtype):\n",
    "    if dtype == trt.int8:\n",
    "        return torch.int8\n",
    "    elif dtype == trt.int32:\n",
    "        return torch.int32\n",
    "    elif dtype == trt.float16:\n",
    "        return torch.float16\n",
    "    elif dtype == trt.float32:\n",
    "        return torch.float32\n",
    "    else:\n",
    "        raise TypeError('%s is not supported by torch' % dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tensorrt_converter('prim::Constant')\n",
    "def convert_constant(ctx, node):\n",
    "    val = next(node.outputs())\n",
    "    sizes = val.type().sizes()[1:]\n",
    "    tensor = node.t('value')\n",
    "    layer = ctx.network.add_constant(tuple(sizes), tensor.cpu().numpy())\n",
    "    ctx.set_trt(val, layer.get_output(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tensorrt_converter('prim::Param')\n",
    "def convert_param(ctx, node):\n",
    "    for val in node.outputs():\n",
    "        if val.isCompleteTensor():\n",
    "            sizes = val.type().sizes()\n",
    "            dtype = val.type().scalarType()\n",
    "            val_trt = ctx.network.add_input(val.debugName(), scalar_type_to_trt(dtype), tuple(sizes[1:]))\n",
    "            ctx.set_trt(val, val_trt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tensorrt_converter('aten::mul')\n",
    "def convert_mul(ctx, node):\n",
    "    inputs_trt = [ctx.get_trt(val) for val in node.inputs()]\n",
    "    layer = ctx.network.add_elementwise(inputs_trt[0], inputs_trt[1], trt.ElementWiseOperation.PROD)\n",
    "    ctx.set_trt(next(node.outputs()), layer.get_output(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val 11\n",
      "Calling converter for aten::mul\n",
      "Val 10\n",
      "Calling converter for aten::mul\n",
      "Val x\n",
      "Calling converter for prim::Param\n",
      "Val 9\n",
      "Calling converter for prim::Constant\n",
      "Val y\n"
     ]
    }
   ],
   "source": [
    "net = torch2trt(model, [data, data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch2trt.utils import trt_network_to_dot_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"480pt\" height=\"305pt\"\n",
       " viewBox=\"0.00 0.00 479.77 305.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 301)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-301 475.7739,-301 475.7739,4 -4,4\"/>\n",
       "<!-- (Unnamed Layer* 0) [Constant] -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>(Unnamed Layer* 0) [Constant]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"124.7889\" cy=\"-279\" rx=\"124.5782\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"124.7889\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(Unnamed Layer* 0) [Constant]</text>\n",
       "</g>\n",
       "<!-- (Unnamed Layer* 1) [ElementWise] -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>(Unnamed Layer* 1) [ElementWise]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"209.7889\" cy=\"-192\" rx=\"141.8751\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"209.7889\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(Unnamed Layer* 1) [ElementWise]</text>\n",
       "</g>\n",
       "<!-- (Unnamed Layer* 0) [Constant]&#45;&gt;(Unnamed Layer* 1) [ElementWise] -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>(Unnamed Layer* 0) [Constant]&#45;&gt;(Unnamed Layer* 1) [ElementWise]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M142.401,-260.9735C154.7097,-248.3752 171.3186,-231.3755 184.9674,-217.4055\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"187.7145,-219.6021 192.1994,-210.0034 182.7075,-214.7103 187.7145,-219.6021\"/>\n",
       "<text text-anchor=\"middle\" x=\"195.2889\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(3, 1, 1)</text>\n",
       "</g>\n",
       "<!-- (Unnamed Layer* 2) [ElementWise] -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>(Unnamed Layer* 2) [ElementWise]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"302.7889\" cy=\"-105\" rx=\"141.8751\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"302.7889\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(Unnamed Layer* 2) [ElementWise]</text>\n",
       "</g>\n",
       "<!-- (Unnamed Layer* 1) [ElementWise]&#45;&gt;(Unnamed Layer* 2) [ElementWise] -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>(Unnamed Layer* 1) [ElementWise]&#45;&gt;(Unnamed Layer* 2) [ElementWise]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M229.0586,-173.9735C242.6505,-161.2586 261.0348,-144.0603 276.0453,-130.0183\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"278.6323,-132.3909 283.544,-123.0034 273.8502,-127.279 278.6323,-132.3909\"/>\n",
       "<text text-anchor=\"middle\" x=\"297.7889\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(3, 224, 224)</text>\n",
       "</g>\n",
       "<!-- (Unnamed Layer* 2) [ElementWise]_output -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>(Unnamed Layer* 2) [ElementWise]_output</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"302.7889\" cy=\"-18\" rx=\"168.97\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"302.7889\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(Unnamed Layer* 2) [ElementWise]_output</text>\n",
       "</g>\n",
       "<!-- (Unnamed Layer* 2) [ElementWise]&#45;&gt;(Unnamed Layer* 2) [ElementWise]_output -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>(Unnamed Layer* 2) [ElementWise]&#45;&gt;(Unnamed Layer* 2) [ElementWise]_output</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M302.7889,-86.9735C302.7889,-75.1918 302.7889,-59.5607 302.7889,-46.1581\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"306.289,-46.0033 302.7889,-36.0034 299.289,-46.0034 306.289,-46.0033\"/>\n",
       "<text text-anchor=\"middle\" x=\"338.7889\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(3, 224, 224)</text>\n",
       "</g>\n",
       "<!-- x -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>x</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"294.7889\" cy=\"-279\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"294.7889\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x</text>\n",
       "</g>\n",
       "<!-- x&#45;&gt;(Unnamed Layer* 1) [ElementWise] -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>x&#45;&gt;(Unnamed Layer* 1) [ElementWise]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M279.9831,-263.8458C267.5078,-251.0769 249.3936,-232.5366 234.6916,-217.4886\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"236.8542,-214.6938 227.3623,-209.9869 231.8472,-219.5856 236.8542,-214.6938\"/>\n",
       "<text text-anchor=\"middle\" x=\"292.7889\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(3, 224, 224)</text>\n",
       "</g>\n",
       "<!-- y -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>y</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"396.7889\" cy=\"-192\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"396.7889\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">y</text>\n",
       "</g>\n",
       "<!-- y&#45;&gt;(Unnamed Layer* 2) [ElementWise] -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>y&#45;&gt;(Unnamed Layer* 2) [ElementWise]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M380.8431,-177.2416C366.8887,-164.3264 346.3237,-145.2929 329.8055,-130.0047\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"331.7847,-127.0675 322.0683,-122.8436 327.0299,-132.2049 331.7847,-127.0675\"/>\n",
       "<text text-anchor=\"middle\" x=\"390.7889\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(3, 224, 224)</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7edeb44b00>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trt_network_to_dot_graph(net.network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graph(%self : ClassType<MyModule>,\n",
       "      %x : Float(1, 3, 224, 224)):\n",
       "  %2 : Float(1, 3, 1, 1) = prim::Constant[value=(1,1,.,.) =   -1.1048  (1,2,.,.) =    0.4352  (1,3,.,.) =    0.5167 [ Variable[CPUFloatType]{1,3,1,1} ]](), scope: MyModule # <ipython-input-104-0e0d3c77cb20>:8:0\n",
       "  %3 : Float(1, 3, 224, 224) = aten::mul(%x, %2), scope: MyModule # <ipython-input-104-0e0d3c77cb20>:8:0\n",
       "  return (%3)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = val.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Float'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "va."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = val.node()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.attributeNames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method PyCapsule.type of x defined in (%self : ClassType<MyModule>, %x : Float(1, 3, 224, 224) = prim::Param()\n",
       ")>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-106-23400b74a02b>(24)get_trt()\n",
      "-> return self.tensors[val.debugName()]  # tensor should now be set...\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  print self.tensors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** SyntaxError: Missing parentheses in call to 'print'. Did you mean print(self.tensors)?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  p self.tensors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  q\n"
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "pdb.pm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graph(%self : ClassType<MyModule>,\n",
       "      %x : Float(1, 3, 224, 224)):\n",
       "  %2 : Float(1, 3, 1, 1) = prim::Constant[value=(1,1,.,.) =   -1.1048  (1,2,.,.) =    0.4352  (1,3,.,.) =    0.5167 [ Variable[CPUFloatType]{1,3,1,1} ]](), scope: MyModule # <ipython-input-104-0e0d3c77cb20>:8:0\n",
       "  %3 : Float(1, 3, 224, 224) = aten::mul(%x, %2), scope: MyModule # <ipython-input-104-0e0d3c77cb20>:8:0\n",
       "  return (%3)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 defined in (%11 : Float(1, 3, 224, 224) = aten::mul(%9, %10), scope: MyModule # <ipython-input-78-2efbdc103968>:8:0\n",
      ")\n",
      "9 defined in (%9 : Float(1, 3, 224, 224) = aten::mul(%x, %8), scope: MyModule # <ipython-input-78-2efbdc103968>:8:0\n",
      ")\n",
      "10 defined in (%10 : Float(1, 3, 1, 1) = prim::Constant[value=(1,1,.,.) =   -0.5971  (1,2,.,.) =    0.3635  (1,3,.,.) =    0.4893 [ Variable[CPUFloatType]{1,3,1,1} ]](), scope: MyModule # <ipython-input-78-2efbdc103968>:8:0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "queue = []\n",
    "call_trace = []\n",
    "\n",
    "queue += graph_outputs(graph)\n",
    "\n",
    "while queue:\n",
    "    val = queue.pop(0)\n",
    "    queue += val_inputs(val)\n",
    "    print(val)\n",
    "    \n",
    "    if val_kind(val) == 'prim::Constant':\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
