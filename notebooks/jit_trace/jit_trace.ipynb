{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_inputs(graph):\n",
    "    \"\"\"Returns inputs of graph as list of torch._C.Value\"\"\"\n",
    "    return list(graph.inputs())\n",
    "\n",
    "def graph_outputs(graph):\n",
    "    \"\"\"Returns outputs of graph as list of torch._C.Value\"\"\"\n",
    "    return list(graph.outputs())\n",
    "\n",
    "def val_size(val):\n",
    "    return val.type().sizes()\n",
    "\n",
    "def val_inputs(val):\n",
    "    return list(val.node().inputs())\n",
    "\n",
    "def val_outputs(val):\n",
    "    return list(val.node().outputs())\n",
    "\n",
    "def val_kind(val):\n",
    "    return val.node().kind()\n",
    "\n",
    "def val_is_tensor(val):\n",
    "    return val.isCompleteTensor()\n",
    "\n",
    "def val_debug_name(val):\n",
    "    return val.debugName()\n",
    "\n",
    "def val_scope_name(val):\n",
    "    return val.node().scopeName()\n",
    "\n",
    "def val_tensor(val):\n",
    "    return val.node().t('value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MyModule, self).__init__()\n",
    "        self.a = torch.randn(1, 3, 1, 1)\n",
    "        \n",
    "    def forward(self, *inputs):\n",
    "#         x = inputs[0]\n",
    "#         y = inputs[1]\n",
    "#         y2 = inputs[1]\n",
    "        return inputs[0] * self.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "TracingCheckError",
     "evalue": "Tracing failed sanity checks!\nERROR: Graphs differed across invocations!\n\tGraph diff:\n\t\t  graph(%self : ClassType<MyModule>,\n\t\t-       %data : Tensor,\n\t\t?        ^^^^\n\t\t+       %1 : Tensor,\n\t\t?        ^\n\t\t        %2 : Tensor):\n\t\t    %3 : Tensor = prim::Constant[value=(1,1,.,.) =    0.1354  (1,2,.,.) =    0.7176  (1,3,.,.) =   -1.7990 [ Variable[CPUFloatType]{1,3,1,1} ]](), scope: MyModule # <ipython-input-87-389b91ea9d51>:11:0\n\t\t-   %4 : Tensor = aten::mul(%data, %3), scope: MyModule # <ipython-input-87-389b91ea9d51>:11:0\n\t\t?                            ^^^^\n\t\t+   %4 : Tensor = aten::mul(%1, %3), scope: MyModule # <ipython-input-87-389b91ea9d51>:11:0\n\t\t?                            ^\n\t\t    return (%4)\n\tFirst diverging operator:\n\tNode diff:\n\t\t- %4 : Tensor = aten::mul(%data, %3), scope: MyModule # <ipython-input-87-389b91ea9d51>:11:0\n\t\t?                          ^^^^\n\t\t+ %4 : Tensor = aten::mul(%1, %3), scope: MyModule # <ipython-input-87-389b91ea9d51>:11:0\n\t\t?                          ^\n\tTrace source location:\n\t\t<ipython-input-87-389b91ea9d51>(11): forward\n\t\t/home/john/.local/lib/python3.6/site-packages/torch/nn/modules/module.py(531): _slow_forward\n\t\t/home/john/.local/lib/python3.6/site-packages/torch/nn/modules/module.py(545): __call__\n\t\t/home/john/.local/lib/python3.6/site-packages/torch/jit/__init__.py(904): trace_module\n\t\t/home/john/.local/lib/python3.6/site-packages/torch/jit/__init__.py(772): trace\n\t\t<ipython-input-88-7c6267a140af>(5): <module>\n\t\t/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py(3326): run_code\n\t\t/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py(3249): run_ast_nodes\n\t\t/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py(3058): run_cell_async\n\t\t/usr/local/lib/python3.6/dist-packages/IPython/core/async_helpers.py(68): _pseudo_sync_runner\n\t\t/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py(2881): _run_cell\n\t\t/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py(2855): run_cell\n\t\t/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py(536): run_cell\n\t\t/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py(294): do_execute\n\t\t/usr/local/lib/python3.6/dist-packages/tornado/gen.py(209): wrapper\n\t\t/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py(542): execute_request\n\t\t/usr/local/lib/python3.6/dist-packages/tornado/gen.py(209): wrapper\n\t\t/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py(272): dispatch_shell\n\t\t/usr/local/lib/python3.6/dist-packages/tornado/gen.py(209): wrapper\n\t\t/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py(365): process_one\n\t\t/usr/local/lib/python3.6/dist-packages/tornado/gen.py(748): run\n\t\t/usr/local/lib/python3.6/dist-packages/tornado/gen.py(787): inner\n\t\t/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py(743): _run_callback\n\t\t/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py(690): <lambda>\n\t\t/usr/lib/python3.6/asyncio/events.py(145): _run\n\t\t/usr/lib/python3.6/asyncio/base_events.py(1451): _run_once\n\t\t/usr/lib/python3.6/asyncio/base_events.py(438): run_forever\n\t\t/usr/local/lib/python3.6/dist-packages/tornado/platform/asyncio.py(148): start\n\t\t/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py(563): start\n\t\t/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py(658): launch_instance\n\t\t/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py(16): <module>\n\t\t/usr/lib/python3.6/runpy.py(85): _run_code\n\t\t/usr/lib/python3.6/runpy.py(193): _run_module_as_main\n\tCheck source location:\n\t\t<ipython-input-87-389b91ea9d51>(11): forward\n\t\t/home/john/.local/lib/python3.6/site-packages/torch/nn/modules/module.py(531): _slow_forward\n\t\t/home/john/.local/lib/python3.6/site-packages/torch/nn/modules/module.py(545): __call__\n\t\t/home/john/.local/lib/python3.6/site-packages/torch/jit/__init__.py(904): trace_module\n\t\t/home/john/.local/lib/python3.6/site-packages/torch/jit/__init__.py(517): _check_trace\n\t\t/home/john/.local/lib/python3.6/site-packages/torch/autograd/grad_mode.py(49): decorate_no_grad\n\t\t/home/john/.local/lib/python3.6/site-packages/torch/jit/__init__.py(914): trace_module\n\t\t/home/john/.local/lib/python3.6/site-packages/torch/jit/__init__.py(772): trace\n\t\t<ipython-input-88-7c6267a140af>(5): <module>\n\t\t/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py(3326): run_code\n\t\t/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py(3249): run_ast_nodes\n\t\t/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py(3058): run_cell_async\n\t\t/usr/local/lib/python3.6/dist-packages/IPython/core/async_helpers.py(68): _pseudo_sync_runner\n\t\t/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py(2881): _run_cell\n\t\t/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py(2855): run_cell\n\t\t/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py(536): run_cell\n\t\t/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py(294): do_execute\n\t\t/usr/local/lib/python3.6/dist-packages/tornado/gen.py(209): wrapper\n\t\t/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py(542): execute_request\n\t\t/usr/local/lib/python3.6/dist-packages/tornado/gen.py(209): wrapper\n\t\t/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py(272): dispatch_shell\n\t\t/usr/local/lib/python3.6/dist-packages/tornado/gen.py(209): wrapper\n\t\t/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py(365): process_one\n\t\t/usr/local/lib/python3.6/dist-packages/tornado/gen.py(748): run\n\t\t/usr/local/lib/python3.6/dist-packages/tornado/gen.py(787): inner\n\t\t/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py(743): _run_callback\n\t\t/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py(690): <lambda>\n\t\t/usr/lib/python3.6/asyncio/events.py(145): _run\n\t\t/usr/lib/python3.6/asyncio/base_events.py(1451): _run_once\n\t\t/usr/lib/python3.6/asyncio/base_events.py(438): run_forever\n\t\t/usr/local/lib/python3.6/dist-packages/tornado/platform/asyncio.py(148): start\n\t\t/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py(563): start\n\t\t/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py(658): launch_instance\n\t\t/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py(16): <module>\n\t\t/usr/lib/python3.6/runpy.py(85): _run_code\n\t\t/usr/lib/python3.6/runpy.py(193): _run_module_as_main\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTracingCheckError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-7c6267a140af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel_jit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_jit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/jit/__init__.py\u001b[0m in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    770\u001b[0m         return trace_module(func, {'forward': example_inputs}, None,\n\u001b[1;32m    771\u001b[0m                             \u001b[0mcheck_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrap_check_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m                             check_tolerance, _force_outplace, _module_class)\n\u001b[0m\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m     if (hasattr(func, '__self__') and isinstance(func.__self__, torch.nn.Module) and\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/jit/__init__.py\u001b[0m in \u001b[0;36mtrace_module\u001b[0;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    912\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                 _check_trace([inputs], func, check_trace_method,\n\u001b[0;32m--> 914\u001b[0;31m                              check_tolerance, _force_outplace, True, _module_class)\n\u001b[0m\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_no_grad\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_no_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/jit/__init__.py\u001b[0m in \u001b[0;36m_check_trace\u001b[0;34m(check_inputs, func, traced_func, check_tolerance, force_outplace, is_trace_module, _module_class)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0mdiag_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_diagnostic_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdiag_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTracingCheckError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdiag_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTracingCheckError\u001b[0m: Tracing failed sanity checks!\nERROR: Graphs differed across invocations!\n\tGraph diff:\n\t\t  graph(%self : ClassType<MyModule>,\n\t\t-       %data : Tensor,\n\t\t?        ^^^^\n\t\t+       %1 : Tensor,\n\t\t?        ^\n\t\t        %2 : Tensor):\n\t\t    %3 : Tensor = prim::Constant[value=(1,1,.,.) =    0.1354  (1,2,.,.) =    0.7176  (1,3,.,.) =   -1.7990 [ Variable[CPUFloatType]{1,3,1,1} ]](), scope: MyModule # <ipython-input-87-389b91ea9d51>:11:0\n\t\t-   %4 : Tensor = aten::mul(%data, %3), scope: MyModule # <ipython-input-87-389b91ea9d51>:11:0\n\t\t?                            ^^^^\n\t\t+   %4 : Tensor = aten::mul(%1, %3), scope: MyModule # <ipython-input-87-389b91ea9d51>:11:0\n\t\t?                            ^\n\t\t    return (%4)\n\tFirst diverging operator:\n\tNode diff:\n\t\t- %4 : Tensor = aten::mul(%data, %3), scope: MyModule # <ipython-input-87-389b91ea9d51>:11:0\n\t\t?                          ^^^^\n\t\t+ %4 : Tensor = aten::mul(%1, %3), scope: MyModule # <ipython-input-87-389b91ea9d51>:11:0\n\t\t?                          ^\n\tTrace source location:\n\t\t<ipython-input-87-389b91ea9d51>(11): forward\n\t\t/home/john/.local/lib/python3.6/site-packages/torch/nn/modules/module.py(531): _slow_forward\n\t\t/home/john/.local/lib/python3.6/site-packages/torch/nn/modules/module.py(545): __call__\n\t\t/home/john/.local/lib/python3.6/site-packages/torch/jit/__init__.py(904): trace_module\n\t\t/home/john/.local/lib/python3.6/site-packages/torch/jit/__init__.py(772): trace\n\t\t<ipython-input-88-7c6267a140af>(5): <module>\n\t\t/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py(3326): run_code\n\t\t/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py(3249): run_ast_nodes\n\t\t/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py(3058): run_cell_async\n\t\t/usr/local/lib/python3.6/dist-packages/IPython/core/async_helpers.py(68): _pseudo_sync_runner\n\t\t/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py(2881): _run_cell\n\t\t/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py(2855): run_cell\n\t\t/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py(536): run_cell\n\t\t/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py(294): do_execute\n\t\t/usr/local/lib/python3.6/dist-packages/tornado/gen.py(209): wrapper\n\t\t/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py(542): execute_request\n\t\t/usr/local/lib/python3.6/dist-packages/tornado/gen.py(209): wrapper\n\t\t/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py(272): dispatch_shell\n\t\t/usr/local/lib/python3.6/dist-packages/tornado/gen.py(209): wrapper\n\t\t/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py(365): process_one\n\t\t/usr/local/lib/python3.6/dist-packages/tornado/gen.py(748): run\n\t\t/usr/local/lib/python3.6/dist-packages/tornado/gen.py(787): inner\n\t\t/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py(743): _run_callback\n\t\t/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py(690): <lambda>\n\t\t/usr/lib/python3.6/asyncio/events.py(145): _run\n\t\t/usr/lib/python3.6/asyncio/base_events.py(1451): _run_once\n\t\t/usr/lib/python3.6/asyncio/base_events.py(438): run_forever\n\t\t/usr/local/lib/python3.6/dist-packages/tornado/platform/asyncio.py(148): start\n\t\t/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py(563): start\n\t\t/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py(658): launch_instance\n\t\t/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py(16): <module>\n\t\t/usr/lib/python3.6/runpy.py(85): _run_code\n\t\t/usr/lib/python3.6/runpy.py(193): _run_module_as_main\n\tCheck source location:\n\t\t<ipython-input-87-389b91ea9d51>(11): forward\n\t\t/home/john/.local/lib/python3.6/site-packages/torch/nn/modules/module.py(531): _slow_forward\n\t\t/home/john/.local/lib/python3.6/site-packages/torch/nn/modules/module.py(545): __call__\n\t\t/home/john/.local/lib/python3.6/site-packages/torch/jit/__init__.py(904): trace_module\n\t\t/home/john/.local/lib/python3.6/site-packages/torch/jit/__init__.py(517): _check_trace\n\t\t/home/john/.local/lib/python3.6/site-packages/torch/autograd/grad_mode.py(49): decorate_no_grad\n\t\t/home/john/.local/lib/python3.6/site-packages/torch/jit/__init__.py(914): trace_module\n\t\t/home/john/.local/lib/python3.6/site-packages/torch/jit/__init__.py(772): trace\n\t\t<ipython-input-88-7c6267a140af>(5): <module>\n\t\t/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py(3326): run_code\n\t\t/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py(3249): run_ast_nodes\n\t\t/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py(3058): run_cell_async\n\t\t/usr/local/lib/python3.6/dist-packages/IPython/core/async_helpers.py(68): _pseudo_sync_runner\n\t\t/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py(2881): _run_cell\n\t\t/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py(2855): run_cell\n\t\t/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py(536): run_cell\n\t\t/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py(294): do_execute\n\t\t/usr/local/lib/python3.6/dist-packages/tornado/gen.py(209): wrapper\n\t\t/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py(542): execute_request\n\t\t/usr/local/lib/python3.6/dist-packages/tornado/gen.py(209): wrapper\n\t\t/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py(272): dispatch_shell\n\t\t/usr/local/lib/python3.6/dist-packages/tornado/gen.py(209): wrapper\n\t\t/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py(365): process_one\n\t\t/usr/local/lib/python3.6/dist-packages/tornado/gen.py(748): run\n\t\t/usr/local/lib/python3.6/dist-packages/tornado/gen.py(787): inner\n\t\t/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py(743): _run_callback\n\t\t/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py(690): <lambda>\n\t\t/usr/lib/python3.6/asyncio/events.py(145): _run\n\t\t/usr/lib/python3.6/asyncio/base_events.py(1451): _run_once\n\t\t/usr/lib/python3.6/asyncio/base_events.py(438): run_forever\n\t\t/usr/local/lib/python3.6/dist-packages/tornado/platform/asyncio.py(148): start\n\t\t/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py(563): start\n\t\t/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py(658): launch_instance\n\t\t/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py(16): <module>\n\t\t/usr/lib/python3.6/runpy.py(85): _run_code\n\t\t/usr/lib/python3.6/runpy.py(193): _run_module_as_main\n"
     ]
    }
   ],
   "source": [
    "model = MyModule()\n",
    "\n",
    "data = torch.zeros((1, 3, 224, 224))\n",
    "\n",
    "model_jit = torch.jit.trace(model, tuple([data, data]))\n",
    "\n",
    "graph = model_jit.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graph(%self : ClassType<MyModule>,\n",
       "      %x : Float(1, 3, 224, 224),\n",
       "      %y2 : Float(1, 3, 224, 224)):\n",
       "  %9 : Float(1, 3, 1, 1) = prim::Constant[value=(1,1,.,.) =   -0.9970  (1,2,.,.) =    1.8650  (1,3,.,.) =    0.2835 [ Variable[CPUFloatType]{1,3,1,1} ]](), scope: MyModule # <ipython-input-84-b769829be4ab>:11:0\n",
       "  %10 : Float(1, 3, 224, 224) = aten::mul(%x, %9), scope: MyModule # <ipython-input-84-b769829be4ab>:11:0\n",
       "  %11 : Float(1, 3, 224, 224) = aten::mul(%10, %y2), scope: MyModule # <ipython-input-84-b769829be4ab>:11:0\n",
       "  return (%11)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[self defined in (%self : ClassType<MyModule>, %x : Float(1, 3, 224, 224), %y : Float(1, 3, 224, 224) = prim::Param()\n",
       " ),\n",
       " x defined in (%self : ClassType<MyModule>, %x : Float(1, 3, 224, 224), %y : Float(1, 3, 224, 224) = prim::Param()\n",
       " ),\n",
       " y defined in (%self : ClassType<MyModule>, %x : Float(1, 3, 224, 224), %y : Float(1, 3, 224, 224) = prim::Param()\n",
       " )]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(graph.inputs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graph(%self : ClassType<MyModule>,\n",
       "      %x : Float(1, 3, 224, 224),\n",
       "      %y : Float(1, 3, 224, 224)):\n",
       "  %9 : Float(1, 3, 1, 1) = prim::Constant[value=(1,1,.,.) =   -0.4956  (1,2,.,.) =   -0.5579  (1,3,.,.) =   -0.2874 [ Variable[CPUFloatType]{1,3,1,1} ]](), scope: MyModule # <ipython-input-3-968050b14635>:8:0\n",
       "  %10 : Float(1, 3, 224, 224) = aten::mul(%x, %9), scope: MyModule # <ipython-input-3-968050b14635>:8:0\n",
       "  %11 : Float(1, 3, 224, 224) = aten::mul(%10, %y), scope: MyModule # <ipython-input-3-968050b14635>:8:0\n",
       "  return (%11)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = list(graph.nodes())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "z(): incompatible function arguments. The following argument types are supported:\n    1. (self: torch._C.Node, arg0: str) -> at::Tensor\n\nInvoked with: %11 : Float(1, 3, 224, 224) = aten::mul(%10, %y), scope: MyModule # <ipython-input-3-968050b14635>:8:0\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-7d0d7185e183>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: z(): incompatible function arguments. The following argument types are supported:\n    1. (self: torch._C.Node, arg0: str) -> at::Tensor\n\nInvoked with: %11 : Float(1, 3, 224, 224) = aten::mul(%10, %y), scope: MyModule # <ipython-input-3-968050b14635>:8:0\n"
     ]
    }
   ],
   "source": [
    "n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONVERTERS = {}\n",
    "\n",
    "\n",
    "def tensorrt_converter(method):\n",
    "    def register_converter(converter):\n",
    "        CONVERTERS[method] = converter\n",
    "        return converter\n",
    "    return register_converter\n",
    "\n",
    "\n",
    "class Context():\n",
    "    \n",
    "    def __init__(self, graph, network, converters=CONVERTERS):\n",
    "        self.graph = graph\n",
    "        self.network = network\n",
    "        self.tensors = {}\n",
    "        self.converters = CONVERTERS\n",
    "\n",
    "    def get_trt(self, val):\n",
    "        print('Val %s' % val.debugName())\n",
    "        if val.debugName() in self.tensors:\n",
    "            return self.tensors[val.debugName()]  # get tensor directly\n",
    "        elif val.node().kind() in self.converters:\n",
    "            print('Calling converter for %s' % val.node().kind())\n",
    "            self.converters[val.node().kind()](self, val.node())  # attempt recursive conversion\n",
    "            return self.tensors[val.debugName()]  # tensor should now be set...\n",
    "        else:\n",
    "            raise KeyError('No converter found for %s' % val.node().kind())\n",
    "    \n",
    "    def set_trt(self, val, val_trt):\n",
    "        if val.debugName() not in self.tensors:\n",
    "            self.tensors[val.debugName()] = val_trt\n",
    "        else:\n",
    "            raise RuntimeException('TensorRT value already found in graph')\n",
    "\n",
    "            \n",
    "def torch2trt(model, data):\n",
    "    \n",
    "    model_jit = torch.jit.trace(model, data)\n",
    "    graph = model_jit.graph\n",
    "    \n",
    "    logger = trt.Logger()\n",
    "    builder = trt.Builder(logger)\n",
    "    \n",
    "    ctx = Context(graph, builder.create_network())\n",
    "    \n",
    "    for output in graph_outputs(graph):\n",
    "        \n",
    "        output_trt = ctx.get_trt(output)\n",
    "        \n",
    "        # now, ctx.trt_tensors\n",
    "        ctx.network.mark_output(output_trt)\n",
    "    return ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalar_type_to_trt(dtype):\n",
    "    if dtype == 'Float':\n",
    "        return trt.float32\n",
    "    elif dtype == 'Half':\n",
    "        return trt.float16\n",
    "    else:\n",
    "        raise TypeError('%s is not supported by tensorrt' % dtype)\n",
    "\n",
    "def torch_dtype_to_trt(dtype):\n",
    "    if dtype == torch.int8:\n",
    "        return trt.int8\n",
    "    elif dtype == torch.int32:\n",
    "        return trt.int32\n",
    "    elif dtype == torch.float16:\n",
    "        return trt.float16\n",
    "    elif dtype == torch.float32:\n",
    "        return trt.float32\n",
    "    else:\n",
    "        raise TypeError('%s is not supported by tensorrt' % dtype)\n",
    "\n",
    "\n",
    "def torch_dtype_from_trt(dtype):\n",
    "    if dtype == trt.int8:\n",
    "        return torch.int8\n",
    "    elif dtype == trt.int32:\n",
    "        return torch.int32\n",
    "    elif dtype == trt.float16:\n",
    "        return torch.float16\n",
    "    elif dtype == trt.float32:\n",
    "        return torch.float32\n",
    "    else:\n",
    "        raise TypeError('%s is not supported by torch' % dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tensorrt_converter('prim::Constant')\n",
    "def convert_constant(ctx, node):\n",
    "    val = next(node.outputs())\n",
    "    sizes = val.type().sizes()[1:]\n",
    "    tensor = node.t('value')\n",
    "    layer = ctx.network.add_constant(tuple(sizes), tensor.cpu().numpy())\n",
    "    layer.name = node.scopeName()\n",
    "    ctx.set_trt(val, layer.get_output(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tensorrt_converter('prim::Param')\n",
    "def convert_param(ctx, node):\n",
    "    for val in node.outputs():\n",
    "        if val.isCompleteTensor():\n",
    "            sizes = val.type().sizes()\n",
    "            dtype = val.type().scalarType()\n",
    "            val_trt = ctx.network.add_input(val.debugName(), scalar_type_to_trt(dtype), tuple(sizes[1:]))\n",
    "            ctx.set_trt(val, val_trt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tensorrt_converter('aten::mul')\n",
    "def convert_mul(ctx, node):\n",
    "    inputs_trt = [ctx.get_trt(val) for val in node.inputs()]\n",
    "    layer = ctx.network.add_elementwise(inputs_trt[0], inputs_trt[1], trt.ElementWiseOperation.PROD)\n",
    "    ctx.set_trt(next(node.outputs()), layer.get_output(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val 11\n",
      "Calling converter for aten::mul\n",
      "Val 10\n",
      "Calling converter for aten::mul\n",
      "Val x\n",
      "Calling converter for prim::Param\n",
      "Val 9\n",
      "Calling converter for prim::Constant\n",
      "Val y\n"
     ]
    }
   ],
   "source": [
    "net = torch2trt(model, [data, data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch2trt.utils import trt_network_to_dot_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"480pt\" height=\"305pt\"\n",
       " viewBox=\"0.00 0.00 479.77 305.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 301)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-301 475.7739,-301 475.7739,4 -4,4\"/>\n",
       "<!-- (Unnamed Layer* 0) [Constant] -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>(Unnamed Layer* 0) [Constant]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"124.7889\" cy=\"-279\" rx=\"124.5782\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"124.7889\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(Unnamed Layer* 0) [Constant]</text>\n",
       "</g>\n",
       "<!-- (Unnamed Layer* 1) [ElementWise] -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>(Unnamed Layer* 1) [ElementWise]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"209.7889\" cy=\"-192\" rx=\"141.8751\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"209.7889\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(Unnamed Layer* 1) [ElementWise]</text>\n",
       "</g>\n",
       "<!-- (Unnamed Layer* 0) [Constant]&#45;&gt;(Unnamed Layer* 1) [ElementWise] -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>(Unnamed Layer* 0) [Constant]&#45;&gt;(Unnamed Layer* 1) [ElementWise]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M142.401,-260.9735C154.7097,-248.3752 171.3186,-231.3755 184.9674,-217.4055\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"187.7145,-219.6021 192.1994,-210.0034 182.7075,-214.7103 187.7145,-219.6021\"/>\n",
       "<text text-anchor=\"middle\" x=\"195.2889\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(3, 1, 1)</text>\n",
       "</g>\n",
       "<!-- (Unnamed Layer* 2) [ElementWise] -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>(Unnamed Layer* 2) [ElementWise]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"302.7889\" cy=\"-105\" rx=\"141.8751\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"302.7889\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(Unnamed Layer* 2) [ElementWise]</text>\n",
       "</g>\n",
       "<!-- (Unnamed Layer* 1) [ElementWise]&#45;&gt;(Unnamed Layer* 2) [ElementWise] -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>(Unnamed Layer* 1) [ElementWise]&#45;&gt;(Unnamed Layer* 2) [ElementWise]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M229.0586,-173.9735C242.6505,-161.2586 261.0348,-144.0603 276.0453,-130.0183\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"278.6323,-132.3909 283.544,-123.0034 273.8502,-127.279 278.6323,-132.3909\"/>\n",
       "<text text-anchor=\"middle\" x=\"297.7889\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(3, 224, 224)</text>\n",
       "</g>\n",
       "<!-- (Unnamed Layer* 2) [ElementWise]_output -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>(Unnamed Layer* 2) [ElementWise]_output</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"302.7889\" cy=\"-18\" rx=\"168.97\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"302.7889\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(Unnamed Layer* 2) [ElementWise]_output</text>\n",
       "</g>\n",
       "<!-- (Unnamed Layer* 2) [ElementWise]&#45;&gt;(Unnamed Layer* 2) [ElementWise]_output -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>(Unnamed Layer* 2) [ElementWise]&#45;&gt;(Unnamed Layer* 2) [ElementWise]_output</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M302.7889,-86.9735C302.7889,-75.1918 302.7889,-59.5607 302.7889,-46.1581\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"306.289,-46.0033 302.7889,-36.0034 299.289,-46.0034 306.289,-46.0033\"/>\n",
       "<text text-anchor=\"middle\" x=\"338.7889\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(3, 224, 224)</text>\n",
       "</g>\n",
       "<!-- x -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>x</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"294.7889\" cy=\"-279\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"294.7889\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x</text>\n",
       "</g>\n",
       "<!-- x&#45;&gt;(Unnamed Layer* 1) [ElementWise] -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>x&#45;&gt;(Unnamed Layer* 1) [ElementWise]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M279.9831,-263.8458C267.5078,-251.0769 249.3936,-232.5366 234.6916,-217.4886\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"236.8542,-214.6938 227.3623,-209.9869 231.8472,-219.5856 236.8542,-214.6938\"/>\n",
       "<text text-anchor=\"middle\" x=\"292.7889\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(3, 224, 224)</text>\n",
       "</g>\n",
       "<!-- y -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>y</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"396.7889\" cy=\"-192\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"396.7889\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">y</text>\n",
       "</g>\n",
       "<!-- y&#45;&gt;(Unnamed Layer* 2) [ElementWise] -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>y&#45;&gt;(Unnamed Layer* 2) [ElementWise]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M380.8431,-177.2416C366.8887,-164.3264 346.3237,-145.2929 329.8055,-130.0047\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"331.7847,-127.0675 322.0683,-122.8436 327.0299,-132.2049 331.7847,-127.0675\"/>\n",
       "<text text-anchor=\"middle\" x=\"390.7889\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(3, 224, 224)</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7edeb44b00>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trt_network_to_dot_graph(net.network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graph(%self : ClassType<MyModule>,\n",
       "      %x : Float(1, 3, 224, 224)):\n",
       "  %2 : Float(1, 3, 1, 1) = prim::Constant[value=(1,1,.,.) =   -1.1048  (1,2,.,.) =    0.4352  (1,3,.,.) =    0.5167 [ Variable[CPUFloatType]{1,3,1,1} ]](), scope: MyModule # <ipython-input-104-0e0d3c77cb20>:8:0\n",
       "  %3 : Float(1, 3, 224, 224) = aten::mul(%x, %2), scope: MyModule # <ipython-input-104-0e0d3c77cb20>:8:0\n",
       "  return (%3)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = val.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Float'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "va."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = val.node()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.attributeNames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method PyCapsule.type of x defined in (%self : ClassType<MyModule>, %x : Float(1, 3, 224, 224) = prim::Param()\n",
       ")>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-106-23400b74a02b>(24)get_trt()\n",
      "-> return self.tensors[val.debugName()]  # tensor should now be set...\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  print self.tensors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** SyntaxError: Missing parentheses in call to 'print'. Did you mean print(self.tensors)?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  p self.tensors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  q\n"
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "pdb.pm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graph(%self : ClassType<MyModule>,\n",
       "      %x : Float(1, 3, 224, 224)):\n",
       "  %2 : Float(1, 3, 1, 1) = prim::Constant[value=(1,1,.,.) =   -1.1048  (1,2,.,.) =    0.4352  (1,3,.,.) =    0.5167 [ Variable[CPUFloatType]{1,3,1,1} ]](), scope: MyModule # <ipython-input-104-0e0d3c77cb20>:8:0\n",
       "  %3 : Float(1, 3, 224, 224) = aten::mul(%x, %2), scope: MyModule # <ipython-input-104-0e0d3c77cb20>:8:0\n",
       "  return (%3)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 defined in (%11 : Float(1, 3, 224, 224) = aten::mul(%9, %10), scope: MyModule # <ipython-input-78-2efbdc103968>:8:0\n",
      ")\n",
      "9 defined in (%9 : Float(1, 3, 224, 224) = aten::mul(%x, %8), scope: MyModule # <ipython-input-78-2efbdc103968>:8:0\n",
      ")\n",
      "10 defined in (%10 : Float(1, 3, 1, 1) = prim::Constant[value=(1,1,.,.) =   -0.5971  (1,2,.,.) =    0.3635  (1,3,.,.) =    0.4893 [ Variable[CPUFloatType]{1,3,1,1} ]](), scope: MyModule # <ipython-input-78-2efbdc103968>:8:0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "queue = []\n",
    "call_trace = []\n",
    "\n",
    "queue += graph_outputs(graph)\n",
    "\n",
    "while queue:\n",
    "    val = queue.pop(0)\n",
    "    queue += val_inputs(val)\n",
    "    print(val)\n",
    "    \n",
    "    if val_kind(val) == 'prim::Constant':\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
